} else {
EY=predict(Outcome.m.list[[j]],newdata=data_e)
Sigma2=predict(Var.m.list[[j]],newdata=data_e,type="response")
Xmat = model.matrix(MSQM.formula,data=data_e)
n.theta=dim(Xmat)[2]
est.eq=function(theta) {
y=as.numeric(Xmat %*% theta)
Pval=pnorm(y,mean=EY,sd=sqrt(Sigma2))
out=rep(NA,n.theta)
for (m in (1:n.theta)) {
out[m] = sum(Xmat[,m]*(Pval-q))
}
out
}
theta.est=nleqslv::nleqslv(x=start.value,fn=est.eq)$x
}
}
return(list(Point=theta.est,delta=coef.list,eta=sigma2.list))
}
#' ICR estimator (standard error)
ICR.f.SE = function(data,q,
Outcome.formula,
Var.formula,
MSQM.formula,
A.names,Outcome.name,delta,eta,theta,tau_n) {
n.steps=length(A.names)
n=dim(data)[1]
beta_sep=cumsum(c(0,c(rbind(sapply(delta,length),sapply(eta,length)))))
beta = c(unlist(do.call(c, Map(list, delta, eta))))
# create the extended datasets and Outcome.m.list and Var.m.list
data_e.list =list()
data_e.list[[1]] = data
for (j in (1:n.steps)) {
Alist=list()
for (i in (1:j)) { Alist[[i]]=c(0,1) }
Alist=expand.grid(Alist);
Aname.now=A.names[(n.steps-j+1):n.steps]
colnames(Alist)=Aname.now
K=2^j
data_e=data[rep(seq_len(nrow(data)), times = K),]
for (k in (1:K)) {
m=(n*(k-1)+1):(n*k)
for (h in (1:j)) { data_e[m,Aname.now[h]]=Alist[k,h] }
}
data_e.list[[j+1]] = data_e
}
######## estimating equation of beta
# type 2 meat, type 3 bread
est.eq.beta = function(beta,type=2) {
#out = matrix(NA,ncol=length(beta),nrow=n)
for (j in (1:n.steps)) {
if (j==1) {
delta.now=beta[(beta_sep[2*j-1]+1):(beta_sep[2*j])];eta.now=beta[(beta_sep[2*j]+1):(beta_sep[2*j+1])]
# estimating equation for delta
X =model.matrix(Outcome.formula[[n.steps-j+1]],data=data_e.list[[j]])
Y = data_e.list[[j]][,Outcome.name]
resi= c(Y - c(X %*% delta.now))
eq.delta.now = X * resi
# estimating equation for eta
data_e.list[[j]]$Sigma2 = resi^2
Xv = model.matrix(as.formula(paste("Sigma2 ~",as.character(Var.formula[[n.steps]])[2])),data=data_e.list[[j]])
Yv = data_e.list[[j]][,"Sigma2"]
resiv = c(Yv - exp(Xv %*% eta.now))
eq.eta.now = Xv * resiv
out = cbind(eq.delta.now,eq.eta.now)
} else {
X = model.matrix(Outcome.formula[[n.steps-j+2]],data=data_e.list[[j]])
EY = c(X %*% delta.now)
Xv = model.matrix(as.formula(Var.formula[[n.steps-j+2]]),data=data_e.list[[j]])
EYv = exp(Xv %*% eta.now)
data_e.list[[j]][,Outcome.name] = EY
delta.now=beta[(beta_sep[2*j-1]+1):(beta_sep[2*j])];eta.now=beta[(beta_sep[2*j]+1):(beta_sep[2*j+1])]
# estimating equation for delta
X =model.matrix(Outcome.formula[[n.steps-j+1]],data=data_e.list[[j]])
Y = data_e.list[[j]][,Outcome.name]
resi= c(Y - c(X %*% delta.now))
eq.delta.now = t(X * resi)
dim(eq.delta.now)=c(dim(eq.delta.now)[1],n,2^(j-1))
eq.delta.now = aperm(eq.delta.now,c(2,1,3))
eq.delta.now = rowSums(eq.delta.now, dims = 2)
# estimating equation for eta
my= c(X %*% delta.now)
data_e.list[[j]]$Sigma2 = EY^2 + EYv - 2*EY*my +my^2
Xv = model.matrix(as.formula(paste("Sigma2 ~",as.character(Var.formula[[n.steps-j+1]])[2])),data=data_e.list[[j]])
Yv = data_e.list[[j]][,"Sigma2"]
resiv = c(Yv - exp(Xv %*% eta.now))
eq.eta.now = t(Xv * resiv)
dim(eq.eta.now)=c(dim(eq.eta.now)[1],n,2^(j-1))
eq.eta.now = aperm(eq.eta.now,c(2,1,3))
eq.eta.now = rowSums(eq.eta.now, dims = 2)
out = cbind(out,eq.delta.now,eq.eta.now)
}
}
if (type==2) {return(out)}
if (type==3) {return(apply(out,2,sum))}
}
## U_beta
Ub = est.eq.beta(beta,type=2)
## I_theta and S_theta_alpha
I_beta = numDeriv::jacobian(est.eq.beta, x=beta, method="simple", type=3)/n
I_beta1 = solve(I_beta,tol=10^(-23))[(beta_sep[2*n.steps-1]+1):beta_sep[length(beta_sep)],]
####### estimating equation of theta
param_sep= c(0,cumsum(c(length(theta),length(delta[[n.steps]]),length(eta[[n.steps]]))))
param = c(theta,delta[[n.steps]],eta[[n.steps]])
# estimating equation of theta
# type 2 meat, type 3 bread
Xmat = model.matrix(MSQM.formula,data=data_e.list[[n.steps+1]])
est.eq=function(theta,type=2) {
delta.now = theta[(param_sep[2]+1):param_sep[3]]
eta.now = theta[(param_sep[3]+1):param_sep[4]]
theta = theta[(param_sep[1]+1):param_sep[2]]
X = model.matrix(Outcome.formula[[1]],data=data_e.list[[n.steps+1]])
EY = c(X %*% delta.now)
Xv = model.matrix(as.formula(Var.formula[[1]]),data=data_e.list[[n.steps+1]])
EYv = exp(Xv %*% eta.now)
y=as.numeric(Xmat %*% theta)
Pval=pnorm(y,mean=EY,sd=sqrt(EYv))
eq.theta.now = t(Xmat * (Pval-q))
dim(eq.theta.now)=c(dim(eq.theta.now)[1],n,2^n.steps)
eq.theta.now = aperm(eq.theta.now,c(2,1,3))
out = rowSums(eq.theta.now, dims = 2)
if (type==2) {return(out)}
if (type==3) {return(apply(out,2,sum))}
}
### sandwich variance
## U_theta
Ut = est.eq(theta=param,type=2)
## I_theta and S_theta_beta
I_esteq = numDeriv::jacobian(est.eq, x=param, method="simple", type=3)/n
I_theta = I_esteq[,(param_sep[1]+1):param_sep[2]]
S_theta_beta = I_esteq[,-c((param_sep[1]+1):param_sep[2])]
## calculate the sandwich variance
# meat
V_icr = crossprod(Ut - t((S_theta_beta) %*% I_beta1 %*% t(Ub)))/n
theta.vcov = (solve(I_theta) %*% V_icr %*% t(solve(I_theta)))/n
return(list(SE=sqrt(abs(diag(theta.vcov))),
SE.TE = sqrt(abs((t(c(0,rep(1,n.steps))) %*% theta.vcov %*% c(0,rep(1,n.steps)))[1,1])),
Ub=Ub,
I_beta=I_beta,
SE.mat = abs(theta.vcov)))
}
#' DR estimator (point estimation)
DR.f.point=function(data,q,
Outcome.formula,
PS.formula,S.formula,
Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,start.value,tau_n) {
n.steps=length(PS.formula)
n=dim(data)[1]
# Obtain PS estimates
PS.m.list=S.m.list=list()
for (j in (1:n.steps)) {
PS.m.list[[j]] = glm(PS.formula[[j]],family=binomial(link="logit"),data=data)
S.m.list[[j]] = glm(S.formula[[j]],family=binomial(link="logit"),data=data)
}
# Obtain Outcome model estimates
coef.list=sigma2.list=Outcome.m.list=Var.m.list=list()
Outcome.m.list[[1]] = lm(Outcome.formula[[n.steps]],data=data)
coef.list[[1]]=coef(Outcome.m.list[[1]]);
EY=predict(Outcome.m.list[[1]],newdata=data)
data$Sigma2 = (Outcome.m.list[[1]]$residuals)^2
Var.m.list[[1]] = glm(as.formula(paste("Sigma2 ~",as.character(Var.formula[[n.steps]])[2])),family=quasipoisson(link="log"),data=data)
sigma2.list[[1]]=Var.m.list[[1]]$coefficients
data_e.list=list();data_e.list[[1]]=data
for (j in (1:(n.steps))) {
# generate the extended dataset
Alist=list()
for (i in (1:j)) { Alist[[i]]=c(0,1) }
Alist=expand.grid(Alist);
Aname.now=A.names[(n.steps-j+1):n.steps]
colnames(Alist)=Aname.now
K=2^j
data_e=data[rep(seq_len(nrow(data)), times = K),]
for (k in (1:K)) {
m=(n*(k-1)+1):(n*k)
for (h in (1:j)) { data_e[m,Aname.now[h]]=Alist[k,h] }
}
data_e.list[[j+1]]=data_e
if (j<n.steps) {
EY=predict(Outcome.m.list[[j]],newdata=data_e)
#EY2=sigma2.list[[j]]+EY^2
data_e[,Outcome.name]=EY
Outcome.m.list[[j+1]] = lm(Outcome.formula[[n.steps-(j+1)+1]],data=data_e)
coef.list[[j+1]] = coef(Outcome.m.list[[j+1]])
my=predict(Outcome.m.list[[j+1]],newdata=data_e)
data_e$Sigma2 = EY^2 + predict(Var.m.list[[j]],newdata=data_e,type="response") - 2*EY*my +my^2
Var.m.list[[j+1]] = glm(as.formula(paste("Sigma2 ~",as.character(Var.formula[[n.steps-(j+1)+1]])[2])),
family=quasipoisson(link="log"),data=data_e)
sigma2.list[[j+1]]=Var.m.list[[j+1]]$coefficients
}
}
# Calculate the IPW and conditional mean for each step
sw.list=s.list=list();mean.list.r=mean.list.l=list()
var.list.r=var.list.l=list()
for (j in (1:n.steps)) {
# calculate the IPW
S.mat=matrix(NA,ncol=n.steps,nrow=dim(data_e.list[[j]]))
IPW.mat = matrix(NA,ncol=n.steps-j+1,nrow=dim(data_e.list[[j]]))
for (m in (1:(n.steps-j+1))) {
ps.now = predict(PS.m.list[[m]],newdata=data_e.list[[j]],type="response")
IPW.mat[,m]=(ps.now^(data_e.list[[j]][,A.names[m]]))*((1-ps.now)^(1-data_e.list[[j]][,A.names[m]]))
}
for (m in (1:(n.steps))) {
s.now = predict(S.m.list[[m]],newdata=data_e.list[[j]],type="response")
S.mat[,m]=(s.now^(data_e.list[[j]][,A.names[m]]))*((1-s.now)^(1-data_e.list[[j]][,A.names[m]]))
}
s.list[[j]] = apply(S.mat,1,prod)
sw.list[[j]]=1/apply(IPW.mat,1,prod)
# calculate the conditional mean and variance
mean.list.r[[j]]=predict(Outcome.m.list[[j]],newdata=data_e.list[[j]])
mean.list.l[[j]]=predict(Outcome.m.list[[j]],newdata=data_e.list[[j+1]])
var.list.r[[j]]=predict(Var.m.list[[j]],newdata=data_e.list[[j]],type="response")
var.list.l[[j]]=predict(Var.m.list[[j]],newdata=data_e.list[[j+1]],type="response")
}
S.mat=matrix(NA,ncol=n.steps,nrow=dim(data_e.list[[n.steps+1]]))
for (m in (1:(n.steps))) {
s.now = predict(S.m.list[[m]],newdata=data_e.list[[n.steps+1]],type="response")
S.mat[,m]=(s.now^(data_e.list[[n.steps+1]][,A.names[m]]))*((1-s.now)^(1-data_e.list[[n.steps+1]][,A.names[m]]))
}
s.list[[n.steps+1]] = apply(S.mat,1,prod)
# Construct the estimating equation
Xmat.list=list()
for (j in (1:(n.steps+1))) {
Xmat.list[[j]]=model.matrix(MSQM.formula,data=data_e.list[[j]])
}
n.theta=dim(Xmat.list[[1]])[2]
est.eq=function(theta) {
expit=function(x,m,gamma=tau_n) {plogis(m-x,scale=gamma)}
y=as.numeric(Xmat.list[[1]] %*% theta)
Pval=expit(x=data[,Outcome.name],m=y)
Fval=pnorm(y,mean=mean.list.r[[1]],sd=sqrt(var.list.r[[1]]))
out=rep(NA,n.theta)
for (m in (1:n.theta)) {
out[m] = sum(Xmat.list[[1]][,m]*s.list[[1]]*sw.list[[1]]*(Pval-Fval))
}
for (j in (1:(n.steps-1))) {
y=as.numeric(Xmat.list[[j+1]] %*% theta)
Pval=pnorm(y,mean=mean.list.l[[j]],sd=sqrt(var.list.l[[j]]))
Fval=pnorm(y,mean=mean.list.r[[j+1]],sd=sqrt(var.list.r[[j+1]]))
for (m in (1:n.theta)) {
out[m] = out[m] + sum(Xmat.list[[j+1]][,m]*s.list[[j+1]]*sw.list[[j+1]]*(Pval-Fval))
}
}
y=as.numeric(Xmat.list[[n.steps+1]] %*% theta)
Pval=pnorm(y,mean=mean.list.l[[n.steps]],sd=sqrt(var.list.l[[n.steps]]))
for (m in (1:n.theta)) {
out[m] = out[m]+sum(Xmat.list[[n.steps+1]][,m]*s.list[[j+2]]*(Pval-q))
}
out
}
theta.est=nleqslv::nleqslv(x=start.value,fn=est.eq)$x
return(list(Point=theta.est))
}
#' DR estimator (standard error)
DR.f.SE=function(data,q,
Outcome.formula,
PS.formula,S.formula,
Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,tau_n,
theta,alpha,alphas,delta,eta,
Ua,Ia,Ub,Ib) {
n.steps=length(PS.formula)
n=dim(data)[1]
# generate the extended dataset
data_e.list=list();data_e.list[[1]]=data
for (j in (1:(n.steps))) {
Alist=list()
for (i in (1:j)) { Alist[[i]]=c(0,1) }
Alist=expand.grid(Alist);
Aname.now=A.names[(n.steps-j+1):n.steps]
colnames(Alist)=Aname.now
K=2^j
data_e=data[rep(seq_len(nrow(data)), times = K),]
for (k in (1:K)) {
m=(n*(k-1)+1):(n*k)
for (h in (1:j)) { data_e[m,Aname.now[h]]=Alist[k,h] }
}
data_e.list[[j+1]]=data_e
}
# all parameters for the MSQM, PS model and Outcome regression models
param_sep=cumsum(c(0,length(theta),c(rbind(sapply(alpha,length),sapply(alphas,length),
sapply(delta,length),sapply(eta,length)))))
param = c(theta,unlist(do.call(c, Map(list, alpha,alphas,delta, eta))))
# estimating equation of theta
# type 2 meat, type 3 bread
est.eq=function(theta,type=2) {
# restore the parameters
alpha=alphas=delta=eta=list()
for (j in (1:n.steps)) {
alpha[[j]] = theta[(param_sep[4*(j-1)+2]+1):param_sep[4*(j-1)+3]]
alphas[[j]] = theta[(param_sep[4*(j-1)+3]+1):param_sep[4*(j-1)+4]]
delta[[j]] = theta[(param_sep[4*(j-1)+4]+1):param_sep[4*(j-1)+5]]
eta[[j]] = theta[(param_sep[4*(j-1)+5]+1):param_sep[4*(j-1)+6]]
}
delta = rev(delta);eta=rev(eta)
theta = theta[1:param_sep[2]]
# Calculate the IPW and conditional mean for each step
sw.list=s.list=list();mean.list.r=mean.list.l=list()
var.list.r=var.list.l=list()
for (j in (1:n.steps)) {
# calculate the IPW
S.mat=matrix(NA,ncol=n.steps,nrow=dim(data_e.list[[j]]))
IPW.mat = matrix(NA,ncol=n.steps-j+1,nrow=dim(data_e.list[[j]]))
for (m in (1:(n.steps-j+1))) {
ps.now = plogis(c(model.matrix(PS.formula[[m]],data=data_e.list[[j]]) %*% alpha[[m]]))
IPW.mat[,m]=(ps.now^(data_e.list[[j]][,A.names[m]]))*((1-ps.now)^(1-data_e.list[[j]][,A.names[m]]))
}
for (m in (1:(n.steps))) {
s.now = plogis(c(model.matrix(S.formula[[m]],data=data_e.list[[j]]) %*% alphas[[m]]))
S.mat[,m]=(s.now^(data_e.list[[j]][,A.names[m]]))*((1-s.now)^(1-data_e.list[[j]][,A.names[m]]))
}
s.list[[j]] = apply(S.mat,1,prod)
sw.list[[j]]=1/apply(IPW.mat,1,prod)
# calculate the conditional mean and variance
mean.list.r[[j]]= c(model.matrix(Outcome.formula[[n.steps-j+1]],data=data_e.list[[j]]) %*% delta[[n.steps-j+1]])
mean.list.l[[j]]= c(model.matrix(Outcome.formula[[n.steps-j+1]],data=data_e.list[[j+1]]) %*% delta[[n.steps-j+1]])
var.list.r[[j]] = exp(model.matrix(Var.formula[[n.steps-j+1]],data=data_e.list[[j]]) %*% eta[[n.steps-j+1]])
var.list.l[[j]]=  exp(model.matrix(Var.formula[[n.steps-j+1]],data=data_e.list[[j+1]]) %*% eta[[n.steps-j+1]])
}
S.mat=matrix(NA,ncol=n.steps,nrow=dim(data_e.list[[n.steps+1]]))
for (m in (1:(n.steps))) {
s.now = plogis(c(model.matrix(S.formula[[m]],data=data_e.list[[n.steps+1]]) %*% alphas[[m]]))
S.mat[,m]=(s.now^(data_e.list[[n.steps+1]][,A.names[m]]))*((1-s.now)^(1-data_e.list[[n.steps+1]][,A.names[m]]))
}
s.list[[n.steps+1]] = apply(S.mat,1,prod)
# Construct the estimating equation
Xmat.list=list()
for (j in (1:(n.steps+1))) {
Xmat.list[[j]]=model.matrix(MSQM.formula,data=data_e.list[[j]])
}
n.theta=param_sep[2]
# construct the estimating equation
expit=function(x,m,gamma=tau_n) {plogis(m-x,scale=gamma)}
y=as.numeric(Xmat.list[[1]] %*% theta)
Pval=expit(x=data[,Outcome.name],m=y)
Fval=pnorm(y,mean=mean.list.r[[1]],sd=sqrt(var.list.r[[1]]))
est.theta.eq= Xmat.list[[1]] * s.list[[1]]*sw.list[[1]]* (Pval-Fval)
for (j in (1:(n.steps-1))) {
y=as.numeric(Xmat.list[[j+1]] %*% theta)
Pval=pnorm(y,mean=mean.list.l[[j]],sd=sqrt(var.list.l[[j]]))
Fval=pnorm(y,mean=mean.list.r[[j+1]],sd=sqrt(var.list.r[[j+1]]))
eq.theta.now = t(Xmat.list[[j+1]] * s.list[[j+1]]*sw.list[[j+1]]* (Pval-Fval))
dim(eq.theta.now)=c(dim(eq.theta.now)[1],n,2^j)
eq.theta.now = aperm(eq.theta.now,c(2,1,3))
est.theta.eq = est.theta.eq + rowSums(eq.theta.now, dims = 2)
}
y=as.numeric(Xmat.list[[n.steps+1]] %*% theta)
Pval=pnorm(y,mean=mean.list.l[[n.steps]],sd=sqrt(var.list.l[[n.steps]]))
eq.theta.now = t(Xmat.list[[n.steps+1]] * s.list[[n.steps+1]]* (Pval-q))
dim(eq.theta.now)=c(dim(eq.theta.now)[1],n,2^(n.steps))
eq.theta.now = aperm(eq.theta.now,c(2,1,3))
est.theta.eq = est.theta.eq + rowSums(eq.theta.now, dims = 2)
if (type==2) {return(est.theta.eq)}
if (type==3) {return(apply(est.theta.eq,2,sum))}
}
### sandwich variance
## U_theta
Ut = est.eq(theta=param,type=2)
## I_theta and S_theta_beta
I_esteq = numDeriv::jacobian(est.eq, x=param, method="simple", type=3)/n
I_theta = I_esteq[,(param_sep[1]+1):param_sep[2]]
alpha_loc=beta_loc=c()
for (j in (1:n.steps)) {
alpha_loc = c(alpha_loc,(param_sep[4*(j-1)+1+1]+1):param_sep[4*(j-1)+1+3])
beta_loc = c(beta_loc,(param_sep[4*(j-1)+1+3]+1):param_sep[4*(j-1)+1+5])
}
S_theta_alpha = I_esteq[,alpha_loc]
S_theta_beta  = I_esteq[,beta_loc]
## calculate the sandwich variance
# meat
V_dr = crossprod(Ut - t((S_theta_beta) %*% solve(Ib,tol=10^(-23)) %*% t(Ub)) + t(S_theta_alpha %*% Ia %*% t(Ua))   )/n
theta.vcov = (solve(I_theta,tol=10^(-23)) %*% V_dr %*% t(solve(I_theta,tol=10^(-23))))/n
return(list(SE=sqrt(abs(diag(theta.vcov))),
SE.TE = sqrt(abs((t(c(0,rep(1,n.steps))) %*% theta.vcov %*% c(0,rep(1,n.steps)))[1,1])),
SE.mat = abs(theta.vcov)
))
}
# naive estimator
naive.e = naive.f(data,q,MSQM.formula)
tau_n = naive.e$tau*dim(data)[1]^(-0.26) #naive.e$tau*
start.value=naive.e$Point
# IPW estimator
ipw.e=IPW.f(data,q,PS.formula,S.formula,MSQM.formula,Outcome.name,start.value,tau_n)
start.value=ipw.e$Point
# ICR estimator
icr.e = ICR.f.point(data,q,Outcome.formula,Var.formula,MSQM.formula,A.names,
Outcome.name,start.value,icr_coef=0)
delta = icr.e$delta
eta = icr.e$eta
theta=icr.e$Point
theta.icr.se=ICR.f.SE(data,q, Outcome.formula,Var.formula,MSQM.formula,A.names,Outcome.name,delta,eta,theta)
# DR estimator
dr.e = DR.f.point(data,q,Outcome.formula,PS.formula,S.formula,Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,start.value,tau_n)
theta=dr.e$Point
alpha=ipw.e$alpha
alphas = ipw.e$alphas
delta = icr.e$delta
eta = icr.e$eta
Ua = ipw.e$Ua
Ia = ipw.e$Ia
Ub = theta.icr.se$Ub
Ib = theta.icr.se$I_beta
theta.dr.se=  DR.f.SE(data,q,Outcome.formula,PS.formula,S.formula,Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,tau_n,theta,alpha,alphas,delta,eta,Ua,Ia,Ub,Ib)
Naive.res=rbind(naive.e$Point,naive.e$SE,naive.e$Point-1.96*naive.e$SE,naive.e$Point+1.96*naive.e$SE)
IPW.res=rbind(ipw.e$Point,ipw.e$SE,ipw.e$Point-1.96*ipw.e$SE,ipw.e$Point+1.96*ipw.e$SE)
ICR.res=rbind(icr.e$Point,theta.icr.se$SE,icr.e$Point-1.96*theta.icr.se$SE,icr.e$Point+1.96*theta.icr.se$SE)
DR.res =rbind(dr.e$Point,theta.dr.se$SE,dr.e$Point-1.96*theta.dr.se$SE,dr.e$Point+1.96*theta.dr.se$SE)
rownames(Naive.res)=rownames(IPW.res)=rownames(ICR.res)=rownames(DR.res)=c("point","SE","CI.lower","CI.upper")
MSQM_coef = list(Unadjusted=Naive.res,IPW=IPW.res,ICR=ICR.res,DR=DR.res)
theta.icr.se$SE.mat
list(IPW=ipw.e$SE.mat,ICR=theta.icr.se$SE.mat,DR=theta.dr.se$SE.mat)
#'                      as.formula(Y~A1+A2+A3+X11+X12+X21+X22),
#'                      as.formula(Y~A1+A2+A3+X11+X12+X21+X22+X31+X32))
#' # specification of outcome variance (k=1,2,3 sequentially)
#' Var.formula =list(as.formula(~A1+A2+A3),
#'                   as.formula(~A1+A2+A3),
#'                   as.formula(~A1+A2+A3))
#'
#' #### Step 3: fit the MSQM
#' msqm.fit(data,q,PS.formula,S.formula,Outcome.formula,Var.formula,
#'          MSQM.formula,A.names,Outcome.name)
msqm.fit=function(data,q,
PS.formula,S.formula,
Outcome.formula,Var.formula,
MSQM.formula,A.names,Outcome.name) {
# naive estimator
naive.e = naive.f(data,q,MSQM.formula)
tau_n = naive.e$tau*dim(data)[1]^(-0.26) #naive.e$tau*
start.value=naive.e$Point
# IPW estimator
ipw.e=IPW.f(data,q,PS.formula,S.formula,MSQM.formula,Outcome.name,start.value,tau_n)
start.value=ipw.e$Point
# ICR estimator
icr.e = ICR.f.point(data,q,Outcome.formula,Var.formula,MSQM.formula,A.names,
Outcome.name,start.value,icr_coef=0)
delta = icr.e$delta
eta = icr.e$eta
theta=icr.e$Point
theta.icr.se=ICR.f.SE(data,q, Outcome.formula,Var.formula,MSQM.formula,A.names,Outcome.name,delta,eta,theta)
# DR estimator
dr.e = DR.f.point(data,q,Outcome.formula,PS.formula,S.formula,Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,start.value,tau_n)
theta=dr.e$Point
alpha=ipw.e$alpha
alphas = ipw.e$alphas
delta = icr.e$delta
eta = icr.e$eta
Ua = ipw.e$Ua
Ia = ipw.e$Ia
Ub = theta.icr.se$Ub
Ib = theta.icr.se$I_beta
theta.dr.se=  DR.f.SE(data,q,Outcome.formula,PS.formula,S.formula,Var.formula=Var.formula,MSQM.formula,
A.names,Outcome.name,tau_n,theta,alpha,alphas,delta,eta,Ua,Ia,Ub,Ib)
IPW.res=rbind(ipw.e$Point,ipw.e$SE,ipw.e$Point-1.96*ipw.e$SE,ipw.e$Point+1.96*ipw.e$SE)
ICR.res=rbind(icr.e$Point,theta.icr.se$SE,icr.e$Point-1.96*theta.icr.se$SE,icr.e$Point+1.96*theta.icr.se$SE)
DR.res =rbind(dr.e$Point,theta.dr.se$SE,dr.e$Point-1.96*theta.dr.se$SE,dr.e$Point+1.96*theta.dr.se$SE)
rownames(IPW.res)=rownames(ICR.res)=rownames(DR.res)=c("point","SE","CI.lower","CI.upper")
MSQM_coef = list(IPW=IPW.res,ICR=ICR.res,DR=DR.res)
MSQM_vcov = list(IPW=ipw.e$SE.mat,ICR=theta.icr.se$SE.mat,DR=theta.dr.se$SE.mat)
return(list(MSQM_coef=MSQM_coef,MSQM_vcov=MSQM_vcov))
}
msqm.fit(data,q,PS.formula,S.formula,Outcome.formula,Var.formula,MSQM.formula,A.names,Outcome.name)
?rmtfit
??rmtfit
set.seed(12345)
data=data.gen(n=500)
MSQM.formula=as.formula(Y~A1+A2+A3)
q=0.5
S.formula=list(as.formula(A1~1),
as.formula(A2~A1),
as.formula(A3~A2))
PS.formula=list(as.formula(A1~X11+X12),
as.formula(A2~A1+X21+X22),
as.formula(A3~A2+X31+X32))
Outcome.formula=list(as.formula(Y~A1+A2+A3+X11+X12),
as.formula(Y~A1+A2+A3+X11+X12+X21+X22),
as.formula(Y~A1+A2+A3+X11+X12+X21+X22+X31+X32))
Var.formula =list(as.formula(~A1+A2+A3),
as.formula(~A1+A2+A3),
as.formula(~A1+A2+A3))
A.names=c("A1","A2","A3")
Outcome.name="Y"
msqm.fit(data,q,PS.formula,S.formula,Outcome.formula,Var.formula,MSQM.formula,A.names,Outcome.name)
sqrt(0.29038872)
data=data.gen(n=500)
head(round(data,2))
document()
devtools::document()
devtools::document()
library(msqm)
devtools::load_all(".")
devtools::use_vignette("introduction")
devtools::document()
devtools::document()
usethat::use_vignette("introduction")
install.packages("usethat")
devtools::use_vignette("introduction")
usethat::use_vignette("introduction")
usethat::use_vignette("introduction")
usethat::use_vignette("introduction")
library("usethat")
usethis::use_vignette("my-vignette")
library(msqm)
msqm.fit()
msqm.fit
?msqm.fit
library(msqm)
set.seed(12345)
data=data.gen(n=500)
head(round(data,2))
